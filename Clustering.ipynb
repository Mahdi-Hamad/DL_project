{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import nyu_dataset\n",
    "import pix2pixHD_model\n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cuda = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = pix2pixHD_model.FeatureEncoder(3, 3, instance_norm=True).cuda(_cuda)\n",
    "encoder.load_state_dict(torch.load('./pix2pixHD_newsegm/models/encoder_170_0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_dataset_validation = nyu_dataset.SegmentationDataset(path_to_datafolder='./datasets/nyu/val/', \n",
    "    transforms=nyu_dataset.SegmentationTransform(train_trainsforms=False, resize=False), \n",
    "    use_instance_segmentation=True)\n",
    "data_loader_val = DataLoader(segmentation_dataset_validation, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "count = 0\n",
    "for image, segm, inst, bord in data_loader_val:\n",
    "    image = Variable(image.cuda(_cuda), requires_grad=False, volatile=True)\n",
    "    segm = Variable(segm.cuda(_cuda), requires_grad=False, volatile=True)\n",
    "    inst = inst.cuda(_cuda)\n",
    "    count += 1\n",
    "    print(count, end='')\n",
    "    if count > 100:\n",
    "        break \n",
    "      \n",
    "    encoded = encoder.forward(image, inst)\n",
    "\n",
    "    array_segm = segm.data.cpu().numpy()\n",
    "    array_encoded = encoded.data.cpu().numpy()\n",
    "    classes = range(array_segm.shape[1])\n",
    "\n",
    "    for k in classes:   \n",
    "        idx = np.argwhere(array_segm[0,k,...]==1)\n",
    "        for x, y in idx:\n",
    "            feature_array = tuple(array_encoded[0, :, x, y].tolist())\n",
    "            dictionary.setdefault(k,set()).add(feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = defaultdict(list)\n",
    "for k, features in dictionary.items():\n",
    "    if len(features)<10:\n",
    "        continue\n",
    "    kmeans = KMeans(n_clusters = 10).fit([list(feat) for feat in features])\n",
    "    k_centers = kmeans.cluster_centers_\n",
    "    cluster_centers[k].append(k_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of instance and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =0 \n",
    "for image, segm, inst, bord in data_loader_val:\n",
    "    image = Variable(image.cuda(_cuda), requires_grad=False, volatile=True)\n",
    "    segm = Variable(segm.cuda(_cuda), requires_grad=False, volatile=True)\n",
    "    inst = inst.cuda(_cuda)\n",
    "    i += 1\n",
    "    if i == 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "classes_map = np.argmax(segm[0].data.cpu().numpy(), axis=0)\n",
    "\n",
    "instance = inst.cpu().numpy()\n",
    "\n",
    "print(len(np.unique(classes_map)))\n",
    "print(len(np.unique(instance)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
