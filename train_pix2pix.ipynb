{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sasha/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import scipy as sp\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from PIL import ImageChops\n",
    "from PIL import ImageEnhance\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import copy\n",
    "import utils\n",
    "import nyu_dataset\n",
    "import pix2pix_model\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmentation_dataset_train = nyu_dataset.SegmentationDataset(transforms=nyu_dataset.SegmentationTransform())\n",
    "data_loader_train = DataLoader(segmentation_dataset_train, batch_size=8, shuffle=True, num_workers=1)\n",
    "\n",
    "segmentation_dataset_validation = nyu_dataset.SegmentationDataset(path_to_datafolder='./datasets/nyu/val/', \n",
    "                                                                  transforms=\n",
    "                                                                  nyu_dataset.SegmentationTransform(False))\n",
    "data_loader_val = DataLoader(segmentation_dataset_validation, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator = pix2pix_model.Generator(num_classes, 3)\n",
    "discriminator = pix2pix_model.Discriminator(num_classes + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data_loader_train, data_loader_val, generator, discriminator, num_epoch=100, lambda_param=10.0):\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    GANLoss = nn.BCELoss()\n",
    "    L1Loss = nn.L1Loss()\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(num_epoch)):\n",
    "        for image_batch, segmentation_batch in data_loader_train:\n",
    "            image_batch = Variable(image_batch, requires_grad=False)\n",
    "            segmentation_batch = Variable(segmentation_batch, requires_grad=False)\n",
    "            \n",
    "            fake_image_batch = generator.forward(segmentation_batch)\n",
    "            \n",
    "            # discriminator step\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            fake_input_discriminator = torch.cat((segmentation_batch, fake_image_batch), 1)\n",
    "            real_input_discriminator = torch.cat((segmentation_batch, image_batch), 1)\n",
    "            \n",
    "            predictions_fake = discriminator.forward(fake_input_discriminator.detach())\n",
    "            predictions_real = discriminator.forward(real_input_discriminator)\n",
    "            \n",
    "            target_tensor = Variable(torch.FloatTensor().fill_(1), requires_grad=False)\n",
    "            loss_discriminator_real = GANLoss(predictions_real, target_tensor)\n",
    "            \n",
    "            target_tensor.data._fill(0)\n",
    "            loss_discriminator_fake = GANLoss(predictions_fake, target_tensor)\n",
    "            \n",
    "            loss_discriminator = (loss_discriminator_fake + loss_discriminator_real)*0.5\n",
    "            loss_discriminator.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # generator step\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            fake_input_discriminator = torch.cat((segmentation_batch, fake_image_batch), 1)         \n",
    "            predictions_fake = discriminator.forward(fake_input_discriminator)\n",
    "            \n",
    "            target_tensor.data._fill(1)\n",
    "            loss_generator_gan = GANLoss(predictions_fake, target_tensor)\n",
    "            \n",
    "            loss_generator_L1 = L1Loss(fake_image_batch, image_batch)*lambda_param\n",
    "            \n",
    "            loss_generator = loss_generator_L1 + loss_generator_gan\n",
    "            loss_generator.backward()\n",
    "            g_optimizer.step()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
