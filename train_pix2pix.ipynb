{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy as sp\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from PIL import ImageChops\n",
    "from PIL import ImageEnhance\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import copy\n",
    "import utils\n",
    "import nyu_dataset\n",
    "import pix2pix_model\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segmentation_dataset_train = nyu_dataset.SegmentationDataset(transforms=nyu_dataset.SegmentationTransform())\n",
    "data_loader_train = DataLoader(segmentation_dataset_train, batch_size=8, shuffle=True, num_workers=1)\n",
    "\n",
    "segmentation_dataset_validation = nyu_dataset.SegmentationDataset(path_to_datafolder='./datasets/nyu/val/', \n",
    "                                                                  transforms=\n",
    "                                                                  nyu_dataset.SegmentationTransform(False))\n",
    "data_loader_val = DataLoader(segmentation_dataset_validation, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator = pix2pix_model.Generator(num_classes, 3).cuda(1)\n",
    "discriminator = pix2pix_model.Discriminator(num_classes + 3).cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data_loader_train, data_loader_val, generator, discriminator, num_epoch=100, lambda_param=10.0):\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    GANLoss = nn.BCELoss()\n",
    "    L1Loss = nn.L1Loss()\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(num_epoch)):\n",
    "        for image_batch, segmentation_batch in data_loader_train:\n",
    "            image_batch = Variable(image_batch.cuda(1), requires_grad=False)\n",
    "            segmentation_batch = Variable(segmentation_batch.cuda(1), requires_grad=False)\n",
    "            \n",
    "            fake_image_batch = generator.forward(segmentation_batch)\n",
    "            \n",
    "            # discriminator step\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            fake_input_discriminator = torch.cat((segmentation_batch, fake_image_batch), 1)\n",
    "            real_input_discriminator = torch.cat((segmentation_batch, image_batch), 1)\n",
    "            \n",
    "            predictions_fake = discriminator.forward(fake_input_discriminator.detach())\n",
    "            predictions_real = discriminator.forward(real_input_discriminator)\n",
    "            \n",
    "            target_tensor = Variable(torch.ones(predictions_fake.shape).cuda(1), requires_grad=False)\n",
    "            loss_discriminator_real = GANLoss(predictions_real, target_tensor)\n",
    "            \n",
    "            target_tensor.data.fill_(0)\n",
    "            loss_discriminator_fake = GANLoss(predictions_fake, target_tensor)\n",
    "            \n",
    "            loss_discriminator = (loss_discriminator_fake + loss_discriminator_real)*0.5\n",
    "            loss_discriminator.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # generator step\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            fake_input_discriminator = torch.cat((segmentation_batch, fake_image_batch), 1)         \n",
    "            predictions_fake = discriminator.forward(fake_input_discriminator)\n",
    "            \n",
    "            target_tensor.data.fill_(1)\n",
    "            loss_generator_gan = GANLoss(predictions_fake, target_tensor)\n",
    "            \n",
    "            loss_generator_L1 = L1Loss(fake_image_batch, image_batch)*lambda_param\n",
    "            \n",
    "            loss_generator = loss_generator_L1 + loss_generator_gan\n",
    "            loss_generator.backward()\n",
    "            g_optimizer.step()\n",
    "        \n",
    "        for image, segmentation in data_loader_val:\n",
    "            segmentation = Variable(segmentation.cuda(1), requires_grad=False)   \n",
    "            generated_image = generator.forward(segmentation)\n",
    "            \n",
    "            print('Val on epoch = {}'.format(epoch))\n",
    "            plt.imshow(np.rollaxis(generated_image.cpu().data.numpy()[0], 0, 3))\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(data_loader_train, data_loader_val, generator, discriminator, num_epoch=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
